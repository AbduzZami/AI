{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":6418531,"sourceType":"datasetVersion","datasetId":3702271}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -U nilearn\n! pip install segmentation-models-3D\n! pip install classification-models-3D\n! pip install visualkeras\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\nimport os\n#General Libraries\n\nimport shutil\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\n#Model libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport visualkeras\n# from keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.utils import plot_model\nimport segmentation_models_3D as sm\nfrom keras import callbacks\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\n\nTRAIN_DATASET_PATH='/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-07T20:25:36.772824Z","iopub.execute_input":"2024-01-07T20:25:36.773223Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nilearn in /opt/conda/lib/python3.10/site-packages (0.10.1)\nCollecting nilearn\n  Downloading nilearn-0.10.2-py3-none-any.whl (10.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from nilearn) (1.2.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from nilearn) (4.9.3)\nRequirement already satisfied: nibabel>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from nilearn) (5.1.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from nilearn) (1.23.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from nilearn) (21.3)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from nilearn) (1.5.3)\nRequirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from nilearn) (2.31.0)\nRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from nilearn) (1.2.2)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from nilearn) (1.11.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->nilearn) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (2023.5.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->nilearn) (3.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"#get the list of all folders. Exclude 'BraTS20_Training_355'. As its segmenation image has some weired name.\nData_dir = [f.path for f in os.scandir('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData') if f.is_dir()]\ndef Name(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\nn=Name(Data_dir)\nN=[t for t in n if t!='BraTS20_Training_355']#This file has weird seg name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Image_explorer:\n    def __init__(self):\n        np.random.seed(4)\n        i=np.random.randint(0,len(N)-1)\n        path=os.path.join(TRAIN_DATASET_PATH,N[i])\n        p=os.listdir(path)\n        t1 = [i for i, s in enumerate(p) if 't1.nii' in s]\n        t2 = [i for i, s in enumerate(p) if 't2.nii' in s]\n        t1ce = [i for i, s in enumerate(p) if 't1ce.nii' in s]\n        seg = [i for i, s in enumerate(p) if 'seg.nii' in s]\n        flair = [i for i, s in enumerate(p) if 'flair.nii' in s]\n        self.test_image_flair=nib.load(os.path.join(path,p[flair[0]])).get_fdata()\n        self.test_image_t1=nib.load(os.path.join(path,p[t1[0]])).get_fdata()\n        self.test_image_t1ce=nib.load(os.path.join(path,p[t1ce[0]])).get_fdata()\n        self.test_image_t2=nib.load(os.path.join(path,p[t2[0]])).get_fdata()\n        self.test_seg=nib.load(os.path.join(path,p[seg[0]])).get_fdata()\n\n    def Axial_View(self,layer):\n        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 5))\n        ax1.imshow(self.test_image_flair[:,:,layer], cmap = 'gray')\n        ax1.set_title('Flair')\n        ax2.imshow(self.test_image_t1[:,:,layer], cmap = 'gray')\n        ax2.set_title('T1')\n        ax3.imshow(self.test_image_t1ce[:,:,layer], cmap = 'gray')\n        ax3.set_title('T1ce')\n        ax4.imshow(self.test_image_t2[:,:,layer], cmap = 'gray')\n        ax4.set_title('T2')\n        ax5.imshow(self.test_seg[:,:,layer])\n        ax5.set_title('Segmented')\n        fig.suptitle('Axial View',fontsize=30)\n        fig.tight_layout()\n        plt.show()\n\n    def Sagittal_View(self,layer):\n        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 5))\n        ax1.imshow(np.rot90(self.test_image_flair[layer,:,:]), cmap = 'gray')\n        ax1.set_title('Flair')\n        ax2.imshow(np.rot90(self.test_image_t1[layer,:,:]), cmap = 'gray')\n        ax2.set_title('T1')\n        ax3.imshow(np.rot90(self.test_image_t1ce[layer,:,:]), cmap = 'gray')\n        ax3.set_title('T1ce')\n        ax4.imshow(np.rot90(self.test_image_t2[layer,:,:]), cmap = 'gray')\n        ax4.set_title('T2')\n        ax5.imshow(np.rot90(self.test_seg[layer,:,:]))\n        ax5.set_title('Segmented')\n        fig.suptitle('Sagittal View',fontsize=30)\n        fig.tight_layout()\n        plt.show()\n\n    def Coronal_View(self,layer):\n        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 5))\n        ax1.imshow(np.rot90(self.test_image_flair[:,layer,:]), cmap = 'gray')\n        ax1.set_title('Flair')\n        ax2.imshow(np.rot90(self.test_image_t1[:,layer,:]), cmap = 'gray')\n        ax2.set_title('T1')\n        ax3.imshow(np.rot90(self.test_image_t1ce[:,layer,:]), cmap = 'gray')\n        ax3.set_title('T1ce')\n        ax4.imshow(np.rot90(self.test_image_t2[:,layer,:]), cmap = 'gray')\n        ax4.set_title('T2')\n        ax5.imshow(np.rot90(self.test_seg[:,layer,:]))\n        ax5.set_title('Segmented')\n        fig.suptitle('Coronal View',fontsize=30)\n        fig.tight_layout()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_flair=nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_flair.nii').get_fdata()\nImage=Image_explorer\nImage().Axial_View(layer=75);\nImage().Sagittal_View(layer=75)\nImage().Coronal_View(layer=150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom skimage.transform import resize\n\ndef resize_3d_image(image, new_shape):\n    resized_image = np.zeros(new_shape)\n    for i in range(image.shape[-1]):\n        resized_image[..., i] = resize(image[..., i], new_shape[:-1], mode='constant', anti_aliasing=True)\n    return resized_image\n\n# Example usage\noriginal_image = np.random.rand(50, 50, 50, 3)  # Example 3D image with shape (50, 50, 50, 3)\nnew_shape = (25, 25, 25, 3)  # New shape for the resized image\n\nresized_image = resize_3d_image(original_image, new_shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom skimage import exposure\n\ndef histogram_equalization_3d(image):\n    equalized_image = np.zeros_like(image)\n\n    for i in range(image.shape[-1]):\n        equalized_image[..., i] = exposure.equalize_hist(image[..., i], nbins=128)\n\n    return equalized_image\n\n# Example usage\noriginal_image = np.random.rand(128, 128, 128, 3)  # Example 3D image with shape (128, 128, 128, 3)\nequalized_image = histogram_equalization_3d(original_image)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, list_IDs, batch_size=1, dim=(128,128,128),shuffle=False,channels=3,num_class=4):\n        'Initialization'\n        self.dim = dim\n        self.n_channels=channels\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.shuffle = shuffle\n        self.num_class=num_class\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Generate data\n        X=np.zeros((self.batch_size,*(self.dim),self.n_channels))\n        Y=np.zeros((self.batch_size,*(self.dim),self.num_class))\n        for i, ID in enumerate(list_IDs_temp):\n            case_path = os.path.join(TRAIN_DATASET_PATH, ID)\n            data_path = os.path.join(case_path, f'{ID}_t1.nii')\n            t1 = nib.load(data_path).get_fdata()\n            st1=MinMaxScaler()\n            t1=st1.fit_transform(t1.reshape(-1,t1.shape[-1])).reshape(t1.shape)\n            data_path = os.path.join(case_path, f'{ID}_flair.nii')\n            flair = nib.load(data_path).get_fdata()\n            stflair=MinMaxScaler()\n            flair=stflair.fit_transform(flair.reshape(-1,flair.shape[-1])).reshape(flair.shape)\n            data_path = os.path.join(case_path, f'{ID}_t1ce.nii')\n            t1ce = nib.load(data_path).get_fdata()\n            st1ce=MinMaxScaler()\n            t1ce=st1ce.fit_transform(t1ce.reshape(-1,t1ce.shape[-1])).reshape(t1ce.shape)\n            data_path = os.path.join(case_path, f'{ID}_seg.nii')\n            seg = nib.load(data_path)\n            x=np.stack([t1,flair,t1ce],axis=3)\n            seg=np.array(seg.get_fdata())\n            seg[seg==4]=3\n            seg=keras.utils.to_categorical(seg,self.num_class)\n            X[i] = resize_3d_image(x, (128,128,128,3))\n            X[i] = histogram_equalization_3d(X[i])\n            Y[i] = resize_3d_image(seg, (128,128,128,4))\n#             X[i]=x[56:184,56:184,13:141]#this slicing is important as GPU will run out of memory if we take the complete image\n#             Y[i]=seg[56:184,56:184,13:141]\n\n        return X, Y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.utils import Sequence\n# from sklearn.preprocessing import MinMaxScaler\n# import numpy as np\n# import nibabel as nib\n# import os\n\n# class DataGenerator(Sequence):\n#     def __init__(self, list_IDs, batch_size=1, dim=(128, 128, 128), shuffle=False, channels=3, num_class=4):\n#         'Initialization'\n#         self.dim = dim\n#         self.n_channels = channels\n#         self.batch_size = batch_size\n#         self.list_IDs = list_IDs\n#         self.shuffle = shuffle\n#         self.num_class = num_class\n#         self.on_epoch_end()\n\n#     def __len__(self):\n#         'Denotes the number of batches per epoch'\n#         return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n#     def __getitem__(self, index):\n#         'Generate one batch of data'\n#         # Generate indexes of the batch\n#         indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n#         # Find list of IDs\n#         list_IDs_temp = [self.list_IDs[k] for k in indexes]\n#         # Generate data\n#         X, y = self.__data_generation(list_IDs_temp)\n#         return X, y\n\n#     def on_epoch_end(self):\n#         self.indexes = np.arange(len(self.list_IDs))\n#         if self.shuffle == True:\n#             np.random.shuffle(self.indexes)\n\n#     def __data_generation(self, list_IDs_temp):\n#         'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n#         # Generate data\n#         X = np.zeros((self.batch_size, *self.dim, self.n_channels))\n#         Y = np.zeros((self.batch_size, *self.dim, self.num_class))\n\n#         for i, ID in enumerate(list_IDs_temp):\n#             case_path = os.path.join(TRAIN_DATASET_PATH, ID)\n\n#             # Load the image and get its original size\n#             data_path_t1 = os.path.join(case_path, f'{ID}_t1.nii')\n#             t1 = nib.load(data_path_t1).get_fdata()\n#             original_size = t1.shape\n\n#             # Normalize and stack channels\n#             st1 = MinMaxScaler()\n#             t1 = st1.fit_transform(t1.reshape(-1, t1.shape[-1])).reshape(t1.shape)\n\n#             data_path_flair = os.path.join(case_path, f'{ID}_flair.nii')\n#             flair = nib.load(data_path_flair).get_fdata()\n#             stflair = MinMaxScaler()\n#             flair = stflair.fit_transform(flair.reshape(-1, flair.shape[-1])).reshape(flair.shape)\n\n#             data_path_t1ce = os.path.join(case_path, f'{ID}_t1ce.nii')\n#             t1ce = nib.load(data_path_t1ce).get_fdata()\n#             st1ce = MinMaxScaler()\n#             t1ce = st1ce.fit_transform(t1ce.reshape(-1, t1ce.shape[-1])).reshape(t1ce.shape)\n\n#             x = np.stack([t1, flair, t1ce], axis=3)\n\n#             # Resize X based on the fixed size\n#             x_resized = tf.image.resize(x, size=self.dim, method=tf.image.ResizeMethod.BILINEAR)\n\n#             seg_path = os.path.join(case_path, f'{ID}_seg.nii')\n#             seg = nib.load(seg_path)\n#             seg = np.array(seg.get_fdata())\n#             seg[seg == 4] = 3\n#             seg = keras.utils.to_categorical(seg, self.num_class)\n\n#             # Resize Y based on the fixed size\n#             seg_resized = tf.image.resize(seg, size=self.dim, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n#             # Assign resized data to the batch\n#             X[i] = x_resized.numpy()\n#             Y[i] = seg_resized.numpy()\n\n#         return X, Y\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_ids = Name(Data_dir);\nTrain_ids=[t for t in Train_ids if t!='BraTS20_Training_355']\ntrain,test=train_test_split(Train_ids,test_size=(1/4),random_state=42)\nTrain,Validation=train_test_split(train,test_size=(1/4),random_state=42)\nTrain_datagen=DataGenerator(Train,batch_size=1)\nVal_datagen=DataGenerator(Validation,batch_size=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(Train))\nprint(len(Validation))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X,y=Train_datagen.__getitem__(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = 0  # checking the 2nd sample of the first batch\nyhat = y[sample]\nyhat = np.argmax(yhat, axis=-1)\n\nlayer = 80\n\nfig, axes = plt.subplots(3, 4, figsize=(15, 10))\n\n# Axial View\naxes[0, 0].imshow(np.rot90(X[sample, layer, :, :, 0]), cmap='gray')\naxes[0, 0].set_title('Axial - Channel 1')\naxes[0, 0].axis('off')\n\naxes[0, 1].imshow(np.rot90(X[sample, layer, :, :, 1]), cmap='gray')\naxes[0, 1].set_title('Axial - Channel 2')\naxes[0, 1].axis('off')\n\naxes[0, 2].imshow(np.rot90(X[sample, layer, :, :, 2]), cmap='gray')\naxes[0, 2].set_title('Axial - Channel 3')\naxes[0, 2].axis('off')\n\naxes[0, 3].imshow(np.rot90(yhat[layer, :, :]))\naxes[0, 3].set_title('Axial - Segmentation Mask')\naxes[0, 3].axis('off')\n\n# Sagittal View\naxes[1, 0].imshow(np.rot90(X[sample, :, layer, :, 0]), cmap='gray')\naxes[1, 0].set_title('Sagittal - Channel 1')\naxes[1, 0].axis('off')\n\naxes[1, 1].imshow(np.rot90(X[sample, :, layer, :, 1]), cmap='gray')\naxes[1, 1].set_title('Sagittal - Channel 2')\naxes[1, 1].axis('off')\n\naxes[1, 2].imshow(np.rot90(X[sample, :, layer, :, 2]), cmap='gray')\naxes[1, 2].set_title('Sagittal - Channel 3')\naxes[1, 2].axis('off')\n\naxes[1, 3].imshow(np.rot90(yhat[:, layer, :]))\naxes[1, 3].set_title('Sagittal - Segmentation Mask')\naxes[1, 3].axis('off')\n\n# Coronal View\naxes[2, 0].imshow(np.rot90(X[sample, :, :, layer, 0]), cmap='gray')\naxes[2, 0].set_title('Coronal - Channel 1')\naxes[2, 0].axis('off')\n\naxes[2, 1].imshow(np.rot90(X[sample, :, :, layer, 1]), cmap='gray')\naxes[2, 1].set_title('Coronal - Channel 2')\naxes[2, 1].axis('off')\n\naxes[2, 2].imshow(np.rot90(X[sample, :, :, layer, 2]), cmap='gray')\naxes[2, 2].set_title('Coronal - Channel 3')\naxes[2, 2].axis('off')\n\naxes[2, 3].imshow(np.rot90(yhat[:, :, layer]))\naxes[2, 3].set_title('Coronal - Segmentation Mask')\naxes[2, 3].axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#original image\nimg_path=Train[0]\npath=os.path.join(TRAIN_DATASET_PATH,img_path)\np=os.listdir(path)\nt1 = [i for i, s in enumerate(p) if 't1.nii' in s]\nt2 = [i for i, s in enumerate(p) if 't2.nii' in s]\nt1ce = [i for i, s in enumerate(p) if 't1ce.nii' in s]\nseg = [i for i, s in enumerate(p) if 'seg.nii' in s]\nflair = [i for i, s in enumerate(p) if 'flair.nii' in s]\ntest_image_flair=nib.load(os.path.join(path,p[flair[0]])).get_fdata()\ntest_image_t1=nib.load(os.path.join(path,p[t1[0]])).get_fdata()\ntest_image_t1ce=nib.load(os.path.join(path,p[t1ce[0]])).get_fdata()\n#test_image_t2=nib.load(os.path.join(path,p[t2[0]])).get_fdata()\ntest_seg=nib.load(os.path.join(path,p[seg[0]])).get_fdata()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer=80\nplt.subplot(2,2,1)\nplt.imshow(np.rot90(test_image_t1[layer,:,:]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,2)\nplt.imshow(np.rot90(test_image_flair[layer,:,:]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,3)\nplt.imshow(np.rot90(test_image_t1ce[layer,:,:]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,4)\nplt.imshow(np.rot90(test_seg[layer,:,:]))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Assuming test_image_t1, test_image_flair, test_image_t1ce, and test_seg are your image arrays\n\nlayer = 80\n\n# Axial View\nplt.subplot(3, 4, 1)\nplt.imshow(np.rot90(test_image_t1[layer, :, :]), cmap='gray')\nplt.title('T1 Axial')\nplt.axis('off')\n\nplt.subplot(3, 4, 2)\nplt.imshow(np.rot90(test_image_flair[layer, :, :]), cmap='gray')\nplt.title('FLAIR Axial')\nplt.axis('off')\n\nplt.subplot(3, 4, 3)\nplt.imshow(np.rot90(test_image_t1ce[layer, :, :]), cmap='gray')\nplt.title('T1CE Axial')\nplt.axis('off')\n\nplt.subplot(3, 4, 4)\nplt.imshow(np.rot90(test_seg[layer, :, :]))\nplt.title('Segmentation Axial')\nplt.axis('off')\n\n# Sagittal View\nplt.subplot(3, 4, 5)\nplt.imshow(np.rot90(test_image_t1[:, layer, :]), cmap='gray')\nplt.title('T1 Sagittal')\nplt.axis('off')\n\nplt.subplot(3, 4, 6)\nplt.imshow(np.rot90(test_image_flair[:, layer, :]), cmap='gray')\nplt.title('FLAIR Sagittal')\nplt.axis('off')\n\nplt.subplot(3, 4, 7)\nplt.imshow(np.rot90(test_image_t1ce[:, layer, :]), cmap='gray')\nplt.title('T1CE Sagittal')\nplt.axis('off')\n\nplt.subplot(3, 4, 8)\nplt.imshow(np.rot90(test_seg[:, layer, :]))\nplt.title('Segmentation Sagittal')\nplt.axis('off')\n\n# Coronal View\nplt.subplot(3, 4, 9)\nplt.imshow(np.rot90(test_image_t1ce[:, :, layer]), cmap='gray')\nplt.title('T1 Coronal')\nplt.axis('off')\n\nplt.subplot(3, 4, 10)\nplt.imshow(np.rot90(test_image_flair[:, :, layer]), cmap='gray')\nplt.title('FLAIR Coronal')\nplt.axis('off')\n\nplt.subplot(3, 4, 11)\nplt.imshow(np.rot90(test_image_t1[:, :, layer]), cmap='gray')\nplt.title('T1CE Coronal')\nplt.axis('off')\n\nplt.subplot(3, 4, 12)\nplt.imshow(np.rot90(test_seg[:, :, layer]))\nplt.title('Segmentation Coronal')\nplt.axis('off')\n\n# Adjust layout to prevent clipping\nplt.tight_layout()\n\n# Display the plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wt=np.array([0.25,0.25,0.25,0.25])\ndiceloss=sm.losses.DiceLoss(class_weights=wt)\nfocalloss=sm.losses.CategoricalFocalLoss()\ntotalloss=diceloss+(1*focalloss)\nmetrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=1\nlr=0.0001\noptim=keras.optimizers.Adam(lr)\nsteps_per_epoch=len(Train)//batch_size\nval_steps_per_epoch=len(Validation)//batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model=sm.Unet(backbone_name='efficientnetb0', input_shape=(128,128,128,3), classes=4, activation='softmax',encoder_weights='imagenet')\n# model.compile(optimizer=optim,loss=totalloss,metrics=metrics)\n# model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\n\ndef conv_block(x, filters, kernel_size=(3, 3, 3), activation='relu', padding='same'):\n    x = layers.Conv3D(filters, kernel_size, activation=activation, padding=padding)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv3D(filters, kernel_size, activation=activation, padding=padding)(x)\n    x = layers.BatchNormalization()(x)\n    return x\n\ndef unet_3d(input_shape=(128, 128, 128, 3), num_classes=4):\n    inputs = layers.Input(input_shape)\n\n    # Encoder\n    conv1 = conv_block(inputs, 32)\n    pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n\n    conv2 = conv_block(pool1, 64)\n    pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n\n    conv3 = conv_block(pool2, 128)\n    pool3 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n\n    # Middle\n    conv4 = conv_block(pool3, 256)\n\n    # Decoder\n    up5 = layers.UpSampling3D(size=(2, 2, 2))(conv4)\n    concat5 = layers.concatenate([conv3, up5], axis=-1)\n    conv5 = conv_block(concat5, 128)\n\n    up6 = layers.UpSampling3D(size=(2, 2, 2))(conv5)\n    concat6 = layers.concatenate([conv2, up6], axis=-1)\n    conv6 = conv_block(concat6, 64)\n\n    up7 = layers.UpSampling3D(size=(2, 2, 2))(conv6)\n    concat7 = layers.concatenate([conv1, up7], axis=-1)\n    conv7 = conv_block(concat7, 32)\n\n    outputs = layers.Conv3D(num_classes, (1, 1, 1), activation='softmax')(conv7)\n\n    model = Model(inputs, outputs, name='3D_UNet')\n    return model\n\n# Instantiate the model\nmodel = unet_3d(input_shape=(128, 128, 128, 3), num_classes=4)\n\n# Compile the model\nmodel.compile(optimizer=optim, loss=totalloss, metrics=metrics)\n\n# Display model summary\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras import layers\n# from tensorflow.keras.models import Model\n\n# def conv_block(x, filters, kernel_size=(3, 3, 3), activation='leakyrelu', padding='same'):\n#     if activation == 'leakyrelu':\n#         activation = layers.LeakyReLU(alpha=0.1)\n#     x = layers.Conv3D(filters, kernel_size, activation=activation, padding=padding)(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Conv3D(filters, kernel_size, activation=activation, padding=padding)(x)\n#     x = layers.BatchNormalization()(x)\n#     return x\n\n# def unet_3d(input_shape=(128, 128, 128, 3), num_classes=4):\n#     inputs = layers.Input(input_shape)\n\n#     # Encoder\n#     conv1 = conv_block(inputs, 32)\n#     pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n\n#     conv2 = conv_block(pool1, 64)\n#     pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n\n#     conv3 = conv_block(pool2, 128)\n#     pool3 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n\n#     conv4 = conv_block(pool3, 256)\n#     pool4 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n\n#     conv5 = conv_block(pool4, 512)\n#     pool5 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv5)\n\n#     conv6 = conv_block(pool5, 1024)\n\n#     # Decoder\n#     up7 = layers.UpSampling3D(size=(2, 2, 2))(conv6)\n#     concat7 = layers.concatenate([conv5, up7], axis=-1)\n#     conv7 = conv_block(concat7, 512)\n\n#     up8 = layers.UpSampling3D(size=(2, 2, 2))(conv7)\n#     concat8 = layers.concatenate([conv4, up8], axis=-1)\n#     conv8 = conv_block(concat8, 256)\n\n#     up9 = layers.UpSampling3D(size=(2, 2, 2))(conv8)\n#     concat9 = layers.concatenate([conv3, up9], axis=-1)\n#     conv9 = conv_block(concat9, 128)\n\n#     up10 = layers.UpSampling3D(size=(2, 2, 2))(conv9)\n#     concat10 = layers.concatenate([conv2, up10], axis=-1)\n#     conv10 = conv_block(concat10, 64)\n\n#     up11 = layers.UpSampling3D(size=(2, 2, 2))(conv10)\n#     concat11 = layers.concatenate([conv1, up11], axis=-1)\n#     conv11 = conv_block(concat11, 32)\n\n#     # Additional Convolutional Blocks\n#     conv12 = conv_block(conv11, 16)\n#     conv13 = conv_block(conv12, 8)\n\n#     outputs = layers.Conv3D(num_classes, (1, 1, 1), activation='softmax')(conv13)\n\n#     model = Model(inputs, outputs, name='3D_UNet')\n#     return model\n\n# # Instantiate the model\n# model = unet_3d(input_shape=(128, 128, 128, 3), num_classes=4)\n\n# # Compile the model\n# model.compile(optimizer=optim, loss=totalloss, metrics=metrics)\n\n# # Display model summary\n# model.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, show_shapes = True,expand_nested = True,dpi = 80)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualkeras.layered_view(model, legend=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nearly_stop = EarlyStopping(monitor='val_loss', mode = 'min', patience=5, restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(Train_datagen,epochs=20,validation_data=Val_datagen,verbose=1,steps_per_epoch=steps_per_epoch,validation_steps=val_steps_per_epoch, callbacks = [early_stop])\n# model.save('my_mdl.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Higher Round trainings**","metadata":{}},{"cell_type":"code","source":"# UNet_3D=load_model('/kaggle/input/unet3d-round2/UNet_3D_best_model_round2_128.keras',custom_objects={'dice_loss_plus_1focal_loss':totalloss,'iou_score':sm.metrics.IOUScore(threshold=0.5)})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNet_3D.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_model(UNet_3D, show_shapes = True,expand_nested = True,dpi = 80)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualkeras.layered_view(UNet_3D, legend=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note the actual model is trained on more than 100 epochs","metadata":{}},{"cell_type":"code","source":"# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n# mc = ModelCheckpoint('UNet_3D_best_model_round3_128.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #30epochs\n# history=UNet_3D.fit(Train_datagen,epochs=40,validation_data=Val_datagen,verbose=1,steps_per_epoch=steps_per_epoch,validation_steps=val_steps_per_epoch,callbacks=[es,mc])\n# #my_model.save('UNet_3D_128_128_128_round_1.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_model('/kaggle/input/brats-weight',custom_objects={'dice_loss_plus_1focal_loss':totalloss,'iou_score':sm.metrics.IOUScore(threshold=0.5)})\n# model.load_weights('/kaggle/input/brats-weight/saved_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Train_accuracy')\nplt.plot(history.history['accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Validation_accuracy')\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Train_IOU_score')\nplt.plot(history.history['iou_score'])\nplt.xlabel('Epochs')\nplt.ylabel('IOU Score')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Validation_IOU_score')\nplt.plot(history.history['val_iou_score'])\nplt.xlabel('Epochs')\nplt.ylabel('IOU Score')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['loss'],label='Train_loss')\nplt.plot(history.history['val_loss'],label='Val_loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X,y=Val_datagen.__getitem__(15)#fetching the first batch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample=0#checking the 2nd sample of first batch\nyhat=y[sample]\nyhat=np.argmax(yhat,axis=-1)\nlayer=80\nplt.subplot(2,2,1)\nplt.imshow(np.rot90(X[sample,layer,:,:,0]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,2)\nplt.imshow(np.rot90(X[sample,layer,:,:,1]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,3)\nplt.imshow(np.rot90(X[sample,layer,:,:,2]))\nplt.axis('off')\nplt.subplot(2,2,4)\nplt.imshow(np.rot90(yhat[layer,:,:]))\nplt.axis('off')\nplt.show()\n\nyhat=np.argmax(y_pred[0],axis=-1)\nplt.imshow(np.rot90(yhat[layer,:,:]))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nimport os\nos.chdir(r'/kaggle/working/')\nFileLink(r'/kaggle/working/UNet_3D_best_model_round3_128.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('saved_model.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('saved_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}