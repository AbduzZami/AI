{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":6418531,"sourceType":"datasetVersion","datasetId":3702271}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font color= 008000 > What is MRI ?\n\nMagnetic Resonance Imaging (MRI) is a non-invasive imaging technology that produces three dimensional detailed anatomical images. It is often used for disease detection, diagnosis, and treatment monitoring. It is based on sophisticated technology that excites and detects the change in the direction of the rotational axis of protons found in the water that makes up living tissues.\n\n# <font color= 008000 > How does MRI work ?\n\nMRIs employ powerful magnets which produce a strong magnetic field that forces protons in the body to align with that field. When a radiofrequency (RF) current is then pulsed through the patient, the protons are stimulated, and spin out of equilibrium, straining against the pull of the magnetic field. When the radiofrequency field is turned off, the protons realign and emits that RF energy, the MRI sensors are able to detect this energy. Check out [Here](https://youtu.be/1CGzk-nV06g). Fourier transformation is used to convert the frequency information contained in the signal from each location in the imaged plane to corresponding intensity levels, which are then displayed as shades of gray in a matrix arrangement of pixels. By varying the sequence of RF pulses applied & collected, different types of images are created. Repetition Time (TR) is the amount of time between successive pulse sequences applied to the same slice. Time to Echo (TE) is the time between the delivery of the RF pulse and the receipt of the echo signal.\n\nTissue can be characterized by two different relaxation times – T1 and T2. T1 (longitudinal relaxation time) is the time constant which determines the rate at which excited protons return to equilibrium. It is a measure of the time taken for spinning protons to realign with the external magnetic field. T2 (transverse relaxation time) is the time constant which determines the rate at which excited protons reach equilibrium or go out of phase with each other. It is a measure of the time taken for spinning protons to lose phase coherence among the nuclei spinning perpendicular to the main field.\n\n**MR Image sequences**\n    \nThe most common MRI sequences are T1-weighted and T2-weighted scans. T1-weighted images are produced by using short TE and TR times. The contrast and brightness of the image are predominately determined by T1 properties of tissue. Conversely, T2-weighted images are produced by using longer TE and TR times. In these images, the contrast and brightness are predominately determined by the T2 properties of tissue.\n\nIn general, T1- and T2-weighted images can be easily differentiated by looking the CSF. CSF is dark on T1-weighted imaging and bright on T2-weighted imaging.\n\nA third commonly used sequence is the Fluid Attenuated Inversion Recovery (Flair). The Flair sequence is similar to a T2-weighted image except that the TE and TR times are very long. By doing so, abnormalities remain bright but normal CSF fluid is attenuated and made dark. This sequence is very sensitive to pathology and makes the differentiation between CSF and an abnormality much easier. The most common sequence for brain tumor detection is Contrast Enhanced T1 weighted MRI. In our project the dataset has 4 channels images (T1,T2,T1ce,Flair)\n\n\n# <font color= 008000 > What is MRI used for ?\n\nMRI scanners are particularly well suited to image the non-bony parts or soft tissues of the body. They differ from computed tomography (CT), in that they do not use the damaging ionizing radiation of x-rays. The brain, spinal cord and nerves, as well as muscles, ligaments, and tendons are seen much more clearly with MRI than with regular x-rays and CT; for this reason MRI is often used to image knee and shoulder injuries.\n\n# <font color= 008000 > What I will do in this project ?\n\nMy main task in this project is to perform a semantic segmentation of Brain MRI image using 3D U-net. I am using the images from BraTS2020 Data set. For accessing the dataset click\n[here](https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation). \n    \n### <font color='289C4E'>Table of contents<font><a class='anchor' id='top'></a>\n1. [Importing Libraries](#pytorch)\n2. [MR Image Exploration](#utility)\n3. [Custom DataGenerator](#dt)  \n4. [Sanity Check of DataGenerator output](#cg)  \n5. [Losses and Metrics](#lm) \n6. [Training](#tr)\n7. [End Notes](#e)  \n# <font color= 008000 > Description of the Dataset\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://www.dropbox.com/scl/fi/rwdbrgyaws75kgdbx0k23/BraTS.jpg?rlkey=pzxawc3x7irhvp80irknsoj4v&raw=1\" alt=\"Heat beating\" style=\"height:600px;margin-top:3rem;\"> </div>\n<center>\n    \nIn the seg file we have label annotations. In numerical values pixels having 0 is not a tumor region. 1 is Necrotic and Non Enhancing Tumor core, 2. Edema, They didn't assign anything with label 3. 4 for Enhancing Tumor. We will later assign 4 with 3. ","metadata":{}},{"cell_type":"markdown","source":"# <font color='289C4E'> 1. Importing Libraries <a class='anchor' id='pytorch'></a> [↑](#top)\nBelow are the required libraries.\n* Because the images are NIfTI files tensorflow can't read them. So we need some neuroimaging library [nibabel](https://nipy.org/nibabel/), [Nilearn](https://nilearn.github.io/stable/index.html)\n* For training purpose we will use segmentation models 3d package [segmentation-models-3D 1.0.4](https://pypi.org/project/segmentation-models-3D/). It has UNet architecture ready, so we don't have to write from scratch.","metadata":{}},{"cell_type":"code","source":"! pip install -U nilearn\n! pip install segmentation-models-3D\n! pip install classification-models-3D\n! pip install visualkeras\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\nimport os\n#General Libraries\n\nimport shutil\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\n#Model libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport visualkeras\nfrom keras.utils.vis_utils import plot_model\nimport segmentation_models_3D as sm\nfrom keras import callbacks\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\n\nTRAIN_DATASET_PATH='/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-29T15:48:06.907720Z","iopub.execute_input":"2023-12-29T15:48:06.908204Z","iopub.status.idle":"2023-12-29T15:49:45.871886Z","shell.execute_reply.started":"2023-12-29T15:48:06.908149Z","shell.execute_reply":"2023-12-29T15:49:45.870886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  <font color= 008000 >2. MR Image Exploration <a class='anchor' id='utility'></a> [↑](#top)","metadata":{}},{"cell_type":"code","source":"#get the list of all folders. Exclude 'BraTS20_Training_355'. As its segmenation image has some weired name.\nData_dir = [f.path for f in os.scandir('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData') if f.is_dir()]\ndef Name(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\nn=Name(Data_dir)\nN=[t for t in n if t!='BraTS20_Training_355']#This file has weird seg name","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:45.873560Z","iopub.execute_input":"2023-12-29T15:49:45.874182Z","iopub.status.idle":"2023-12-29T15:49:45.930625Z","shell.execute_reply.started":"2023-12-29T15:49:45.874151Z","shell.execute_reply":"2023-12-29T15:49:45.929688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Image_explorer:\n    def __init__(self):\n        np.random.seed(4)\n        i=np.random.randint(0,len(N)-1)\n        path=os.path.join(TRAIN_DATASET_PATH,N[i])\n        p=os.listdir(path)\n        t1 = [i for i, s in enumerate(p) if 't1.nii' in s]\n        t2 = [i for i, s in enumerate(p) if 't2.nii' in s]\n        t1ce = [i for i, s in enumerate(p) if 't1ce.nii' in s]\n        seg = [i for i, s in enumerate(p) if 'seg.nii' in s]\n        flair = [i for i, s in enumerate(p) if 'flair.nii' in s]\n        self.test_image_flair=nib.load(os.path.join(path,p[flair[0]])).get_fdata()\n        self.test_image_t1=nib.load(os.path.join(path,p[t1[0]])).get_fdata()\n        self.test_image_t1ce=nib.load(os.path.join(path,p[t1ce[0]])).get_fdata()\n        self.test_image_t2=nib.load(os.path.join(path,p[t2[0]])).get_fdata()\n        self.test_seg=nib.load(os.path.join(path,p[seg[0]])).get_fdata()\n\n    def Axial_View(self,layer):\n        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 5))\n        ax1.imshow(self.test_image_flair[:,:,layer], cmap = 'gray')\n        ax1.set_title('Flair')\n        ax2.imshow(self.test_image_t1[:,:,layer], cmap = 'gray')\n        ax2.set_title('T1')\n        ax3.imshow(self.test_image_t1ce[:,:,layer], cmap = 'gray')\n        ax3.set_title('T1ce')\n        ax4.imshow(self.test_image_t2[:,:,layer], cmap = 'gray')\n        ax4.set_title('T2')\n        ax5.imshow(self.test_seg[:,:,layer])\n        ax5.set_title('Segmented')\n        fig.suptitle('Axial View',fontsize=30)\n        fig.tight_layout()\n        plt.show()\n\n    def Sagittal_View(self,layer):\n        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 5))\n        ax1.imshow(np.rot90(self.test_image_flair[layer,:,:]), cmap = 'gray')\n        ax1.set_title('Flair')\n        ax2.imshow(np.rot90(self.test_image_t1[layer,:,:]), cmap = 'gray')\n        ax2.set_title('T1')\n        ax3.imshow(np.rot90(self.test_image_t1ce[layer,:,:]), cmap = 'gray')\n        ax3.set_title('T1ce')\n        ax4.imshow(np.rot90(self.test_image_t2[layer,:,:]), cmap = 'gray')\n        ax4.set_title('T2')\n        ax5.imshow(np.rot90(self.test_seg[layer,:,:]))\n        ax5.set_title('Segmented')\n        fig.suptitle('Sagittal View',fontsize=30)\n        fig.tight_layout()\n        plt.show()\n\n    def Coronal_View(self,layer):\n        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 5))\n        ax1.imshow(np.rot90(self.test_image_flair[:,layer,:]), cmap = 'gray')\n        ax1.set_title('Flair')\n        ax2.imshow(np.rot90(self.test_image_t1[:,layer,:]), cmap = 'gray')\n        ax2.set_title('T1')\n        ax3.imshow(np.rot90(self.test_image_t1ce[:,layer,:]), cmap = 'gray')\n        ax3.set_title('T1ce')\n        ax4.imshow(np.rot90(self.test_image_t2[:,layer,:]), cmap = 'gray')\n        ax4.set_title('T2')\n        ax5.imshow(np.rot90(self.test_seg[:,layer,:]))\n        ax5.set_title('Segmented')\n        fig.suptitle('Coronal View',fontsize=30)\n        fig.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:45.932345Z","iopub.execute_input":"2023-12-29T15:49:45.932756Z","iopub.status.idle":"2023-12-29T15:49:45.953818Z","shell.execute_reply.started":"2023-12-29T15:49:45.932721Z","shell.execute_reply":"2023-12-29T15:49:45.952947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_flair=nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_flair.nii').get_fdata()\nImage=Image_explorer\nImage().Axial_View(layer=75);\nImage().Sagittal_View(layer=75)\nImage().Coronal_View(layer=150)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:45.955808Z","iopub.execute_input":"2023-12-29T15:49:45.956094Z","iopub.status.idle":"2023-12-29T15:49:50.965079Z","shell.execute_reply.started":"2023-12-29T15:49:45.956070Z","shell.execute_reply":"2023-12-29T15:49:50.964143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='289C4E'> 3. Custom DataGenerator <a class='anchor' id='dt'></a> [↑](#top)\nAs mentioned already tensorflow can't read the nifti files. So we can't use their inbuilt ImageDataGenerator. But Keras has its cutom data generator pipeline in its utils.Sequence Module. Some part of code I am motivated from [here](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly). We have to follow this exact pipeline and can change the __data_generation function as per our requirement.","metadata":{}},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    def __init__(self, list_IDs, batch_size=1, dim=(128,128,128),shuffle=False,channels=3,num_class=4):\n        'Initialization'\n        self.dim = dim\n        self.n_channels=channels\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.shuffle = shuffle\n        self.num_class=num_class\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Generate data\n        X=np.zeros((self.batch_size,*(self.dim),self.n_channels))\n        Y=np.zeros((self.batch_size,*(self.dim),self.num_class))\n        for i, ID in enumerate(list_IDs_temp):\n            case_path = os.path.join(TRAIN_DATASET_PATH, ID)\n            data_path = os.path.join(case_path, f'{ID}_t1.nii')\n            t1 = nib.load(data_path).get_fdata()\n            st1=MinMaxScaler()\n            t1=st1.fit_transform(t1.reshape(-1,t1.shape[-1])).reshape(t1.shape)\n            data_path = os.path.join(case_path, f'{ID}_flair.nii')\n            flair = nib.load(data_path).get_fdata()\n            stflair=MinMaxScaler()\n            flair=stflair.fit_transform(flair.reshape(-1,flair.shape[-1])).reshape(flair.shape)\n            data_path = os.path.join(case_path, f'{ID}_t1ce.nii')\n            t1ce = nib.load(data_path).get_fdata()\n            st1ce=MinMaxScaler()\n            t1ce=st1ce.fit_transform(t1ce.reshape(-1,t1ce.shape[-1])).reshape(t1ce.shape)\n            data_path = os.path.join(case_path, f'{ID}_seg.nii')\n            seg = nib.load(data_path)\n            x=np.stack([t1,flair,t1ce],axis=3)\n            seg=np.array(seg.get_fdata())\n            seg[seg==4]=3\n            seg=keras.utils.to_categorical(seg,self.num_class)\n            X[i]=x[56:184,56:184,13:141]#this slicing is important as GPU will run out of memory if we take the complete image\n            Y[i]=seg[56:184,56:184,13:141]\n\n        return X, Y","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:50.966808Z","iopub.execute_input":"2023-12-29T15:49:50.967204Z","iopub.status.idle":"2023-12-29T15:49:50.983753Z","shell.execute_reply.started":"2023-12-29T15:49:50.967168Z","shell.execute_reply":"2023-12-29T15:49:50.982706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_ids = Name(Data_dir);\nTrain_ids=[t for t in Train_ids if t!='BraTS20_Training_355']\ntrain,test=train_test_split(Train_ids,test_size=(1/4),random_state=42)\nTrain,Validation=train_test_split(train,test_size=(1/4),random_state=42)\nTrain_datagen=DataGenerator(Train,batch_size=1)\nVal_datagen=DataGenerator(Validation,batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:49:50.985118Z","iopub.execute_input":"2023-12-29T15:49:50.985475Z","iopub.status.idle":"2023-12-29T15:49:51.013261Z","shell.execute_reply.started":"2023-12-29T15:49:50.985442Z","shell.execute_reply":"2023-12-29T15:49:51.012399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='289C4E'>4. Sanity Check of DataGenerator output <a class='anchor' id='cg'></a> [↑](#top)","metadata":{}},{"cell_type":"code","source":"X,y=Train_datagen.__getitem__(10)#fetching the first batch","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:02:46.863151Z","iopub.execute_input":"2023-12-29T16:02:46.863935Z","iopub.status.idle":"2023-12-29T16:02:47.924684Z","shell.execute_reply.started":"2023-12-29T16:02:46.863892Z","shell.execute_reply":"2023-12-29T16:02:47.923668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:02:49.589376Z","iopub.execute_input":"2023-12-29T16:02:49.590410Z","iopub.status.idle":"2023-12-29T16:02:49.595650Z","shell.execute_reply.started":"2023-12-29T16:02:49.590364Z","shell.execute_reply":"2023-12-29T16:02:49.594672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample=0#checking the 2nd sample of first batch\nyhat=y[sample]\nyhat=np.argmax(yhat,axis=-1)\nlayer=80\nplt.subplot(2,2,1)\nplt.imshow(np.rot90(X[sample,layer,:,:,0]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,2)\nplt.imshow(np.rot90(X[sample,layer,:,:,1]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,3)\nplt.imshow(np.rot90(X[sample,layer,:,:,2]))\nplt.axis('off')\nplt.subplot(2,2,4)\nplt.imshow(np.rot90(yhat[layer,:,:]))\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:02:51.559547Z","iopub.execute_input":"2023-12-29T16:02:51.560368Z","iopub.status.idle":"2023-12-29T16:02:51.821937Z","shell.execute_reply.started":"2023-12-29T16:02:51.560324Z","shell.execute_reply":"2023-12-29T16:02:51.815423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#original image\nimg_path=Train[1]\npath=os.path.join(TRAIN_DATASET_PATH,img_path)\np=os.listdir(path)\nt1 = [i for i, s in enumerate(p) if 't1.nii' in s]\nt2 = [i for i, s in enumerate(p) if 't2.nii' in s]\nt1ce = [i for i, s in enumerate(p) if 't1ce.nii' in s]\nseg = [i for i, s in enumerate(p) if 'seg.nii' in s]\nflair = [i for i, s in enumerate(p) if 'flair.nii' in s]\ntest_image_flair=nib.load(os.path.join(path,p[flair[0]])).get_fdata()\ntest_image_t1=nib.load(os.path.join(path,p[t1[0]])).get_fdata()\ntest_image_t1ce=nib.load(os.path.join(path,p[t1ce[0]])).get_fdata()\n#test_image_t2=nib.load(os.path.join(path,p[t2[0]])).get_fdata()\ntest_seg=nib.load(os.path.join(path,p[seg[0]])).get_fdata()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:09.169272Z","iopub.execute_input":"2023-12-29T15:50:09.169970Z","iopub.status.idle":"2023-12-29T15:50:09.815564Z","shell.execute_reply.started":"2023-12-29T15:50:09.169904Z","shell.execute_reply":"2023-12-29T15:50:09.814509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer=136\nplt.subplot(2,2,1)\nplt.imshow(np.rot90(test_image_t1[layer,:,:]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,2)\nplt.imshow(np.rot90(test_image_flair[layer,:,:]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,3)\nplt.imshow(np.rot90(test_image_t1ce[layer,:,:]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,4)\nplt.imshow(np.rot90(test_seg[layer,:,:]))\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:09.817588Z","iopub.execute_input":"2023-12-29T15:50:09.817985Z","iopub.status.idle":"2023-12-29T15:50:10.034780Z","shell.execute_reply.started":"2023-12-29T15:50:09.817950Z","shell.execute_reply":"2023-12-29T15:50:10.033570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='289C4E'>4. Losses and Metrics <a class='anchor' id='lm'></a> [↑](#top)\nWe will use a special loss function used in this domain called ","metadata":{}},{"cell_type":"code","source":"wt=np.array([0.25,0.25,0.25,0.25])\ndiceloss=sm.losses.DiceLoss(class_weights=wt)\nfocalloss=sm.losses.CategoricalFocalLoss()\ntotalloss=diceloss+(1*focalloss)\nmetrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:10.036713Z","iopub.execute_input":"2023-12-29T15:50:10.037490Z","iopub.status.idle":"2023-12-29T15:50:10.044837Z","shell.execute_reply.started":"2023-12-29T15:50:10.037444Z","shell.execute_reply":"2023-12-29T15:50:10.043592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=1\nlr=0.0001\noptim=keras.optimizers.Adam(lr)\nsteps_per_epoch=len(Train)//batch_size\nval_steps_per_epoch=len(Validation)//batch_size","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:10.048498Z","iopub.execute_input":"2023-12-29T15:50:10.049294Z","iopub.status.idle":"2023-12-29T15:50:10.063149Z","shell.execute_reply.started":"2023-12-29T15:50:10.049249Z","shell.execute_reply":"2023-12-29T15:50:10.061953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=sm.Unet(backbone_name='vgg16', input_shape=(128,128,128,3), classes=4, activation='softmax',encoder_weights='imagenet')\nmodel.compile(optimizer=optim,loss=totalloss,metrics=metrics)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:10.064978Z","iopub.execute_input":"2023-12-29T15:50:10.065742Z","iopub.status.idle":"2023-12-29T15:50:13.707758Z","shell.execute_reply.started":"2023-12-29T15:50:10.065698Z","shell.execute_reply":"2023-12-29T15:50:13.706325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"plot_model(model, show_shapes = True,expand_nested = True,dpi = 80)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:13.709020Z","iopub.execute_input":"2023-12-29T15:50:13.709384Z","iopub.status.idle":"2023-12-29T15:50:13.719433Z","shell.execute_reply.started":"2023-12-29T15:50:13.709350Z","shell.execute_reply":"2023-12-29T15:50:13.718348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"visualkeras.layered_view(model, legend=True)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:13.720652Z","iopub.execute_input":"2023-12-29T15:50:13.720920Z","iopub.status.idle":"2023-12-29T15:50:13.741458Z","shell.execute_reply.started":"2023-12-29T15:50:13.720896Z","shell.execute_reply":"2023-12-29T15:50:13.740177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='289C4E'>5. Training <a class='anchor' id='tr'></a> [↑](#top)\n**1st Round Training**","metadata":{}},{"cell_type":"code","source":"history=model.fit(Train_datagen,epochs=1,validation_data=Val_datagen,verbose=1,steps_per_epoch=steps_per_epoch,validation_steps=val_steps_per_epoch)\n# model.save('my_mdl.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:51:03.972863Z","iopub.execute_input":"2023-12-29T15:51:03.973301Z","iopub.status.idle":"2023-12-29T15:59:42.094731Z","shell.execute_reply.started":"2023-12-29T15:51:03.973267Z","shell.execute_reply":"2023-12-29T15:59:42.093704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Higher Round trainings**","metadata":{}},{"cell_type":"code","source":"# UNet_3D=load_model('/kaggle/input/unet3d-round2/UNet_3D_best_model_round2_128.keras',custom_objects={'dice_loss_plus_1focal_loss':totalloss,'iou_score':sm.metrics.IOUScore(threshold=0.5)})","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:58.210647Z","iopub.status.idle":"2023-12-29T15:50:58.211016Z","shell.execute_reply.started":"2023-12-29T15:50:58.210832Z","shell.execute_reply":"2023-12-29T15:50:58.210849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNet_3D.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:58.212948Z","iopub.status.idle":"2023-12-29T15:50:58.213314Z","shell.execute_reply.started":"2023-12-29T15:50:58.213146Z","shell.execute_reply":"2023-12-29T15:50:58.213163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_model(UNet_3D, show_shapes = True,expand_nested = True,dpi = 80)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:58.214564Z","iopub.status.idle":"2023-12-29T15:50:58.214901Z","shell.execute_reply.started":"2023-12-29T15:50:58.214737Z","shell.execute_reply":"2023-12-29T15:50:58.214753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualkeras.layered_view(UNet_3D, legend=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:58.216692Z","iopub.status.idle":"2023-12-29T15:50:58.217070Z","shell.execute_reply.started":"2023-12-29T15:50:58.216871Z","shell.execute_reply":"2023-12-29T15:50:58.216887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note the actual model is trained on more than 100 epochs","metadata":{}},{"cell_type":"code","source":"# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n# mc = ModelCheckpoint('UNet_3D_best_model_round3_128.keras', monitor='val_loss', mode='min', verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:58.218354Z","iopub.status.idle":"2023-12-29T15:50:58.218665Z","shell.execute_reply.started":"2023-12-29T15:50:58.218510Z","shell.execute_reply":"2023-12-29T15:50:58.218525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #30epochs\n# history=UNet_3D.fit(Train_datagen,epochs=40,validation_data=Val_datagen,verbose=1,steps_per_epoch=steps_per_epoch,validation_steps=val_steps_per_epoch,callbacks=[es,mc])\n# #my_model.save('UNet_3D_128_128_128_round_1.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:58.220456Z","iopub.status.idle":"2023-12-29T15:50:58.220768Z","shell.execute_reply.started":"2023-12-29T15:50:58.220613Z","shell.execute_reply":"2023-12-29T15:50:58.220628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNet_3D=load_model('/kaggle/input/trained-unet-3d/UNet_3D_best_model_round3_128.keras',custom_objects={'dice_loss_plus_1focal_loss':totalloss,'iou_score':sm.metrics.IOUScore(threshold=0.5)})","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:50:58.222661Z","iopub.status.idle":"2023-12-29T15:50:58.223038Z","shell.execute_reply.started":"2023-12-29T15:50:58.222841Z","shell.execute_reply":"2023-12-29T15:50:58.222858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Train_accuracy')\nplt.plot(history.history['accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:59:52.571314Z","iopub.execute_input":"2023-12-29T15:59:52.572033Z","iopub.status.idle":"2023-12-29T15:59:52.820687Z","shell.execute_reply.started":"2023-12-29T15:59:52.571997Z","shell.execute_reply":"2023-12-29T15:59:52.819694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Validation_accuracy')\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:59:52.822272Z","iopub.execute_input":"2023-12-29T15:59:52.822578Z","iopub.status.idle":"2023-12-29T15:59:53.067886Z","shell.execute_reply.started":"2023-12-29T15:59:52.822551Z","shell.execute_reply":"2023-12-29T15:59:53.066917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Train_IOU_score')\nplt.plot(history.history['iou_score'])\nplt.xlabel('Epochs')\nplt.ylabel('IOU Score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:59:53.069240Z","iopub.execute_input":"2023-12-29T15:59:53.069628Z","iopub.status.idle":"2023-12-29T15:59:53.340128Z","shell.execute_reply.started":"2023-12-29T15:59:53.069593Z","shell.execute_reply":"2023-12-29T15:59:53.339151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Validation_IOU_score')\nplt.plot(history.history['val_iou_score'])\nplt.xlabel('Epochs')\nplt.ylabel('IOU Score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:59:53.342708Z","iopub.execute_input":"2023-12-29T15:59:53.343056Z","iopub.status.idle":"2023-12-29T15:59:53.622553Z","shell.execute_reply.started":"2023-12-29T15:59:53.343026Z","shell.execute_reply":"2023-12-29T15:59:53.621598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history.history['loss'],label='Train_loss')\nplt.plot(history.history['val_loss'],label='Val_loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T15:59:53.623892Z","iopub.execute_input":"2023-12-29T15:59:53.624296Z","iopub.status.idle":"2023-12-29T15:59:53.838159Z","shell.execute_reply.started":"2023-12-29T15:59:53.624255Z","shell.execute_reply":"2023-12-29T15:59:53.837191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X,y=Val_datagen.__getitem__(1)#fetching the first batch","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:06:40.359399Z","iopub.execute_input":"2023-12-29T16:06:40.359790Z","iopub.status.idle":"2023-12-29T16:06:41.401077Z","shell.execute_reply.started":"2023-12-29T16:06:40.359758Z","shell.execute_reply":"2023-12-29T16:06:41.400248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(X)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:06:42.447951Z","iopub.execute_input":"2023-12-29T16:06:42.448305Z","iopub.status.idle":"2023-12-29T16:06:42.899982Z","shell.execute_reply.started":"2023-12-29T16:06:42.448278Z","shell.execute_reply":"2023-12-29T16:06:42.899119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample=0#checking the 2nd sample of first batch\nyhat=y[sample]\nyhat=np.argmax(yhat,axis=-1)\nlayer=80\nplt.subplot(2,2,1)\nplt.imshow(np.rot90(X[sample,layer,:,:,0]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,2)\nplt.imshow(np.rot90(X[sample,layer,:,:,1]),cmap='gray')\nplt.axis('off')\nplt.subplot(2,2,3)\nplt.imshow(np.rot90(X[sample,layer,:,:,2]))\nplt.axis('off')\nplt.subplot(2,2,4)\nplt.imshow(np.rot90(yhat[layer,:,:]))\nplt.axis('off')\nplt.show()\n\nyhat=np.argmax(y_pred[0],axis=-1)\nplt.imshow(np.rot90(yhat[layer,:,:]))\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:06:45.059483Z","iopub.execute_input":"2023-12-29T16:06:45.060430Z","iopub.status.idle":"2023-12-29T16:06:45.435503Z","shell.execute_reply.started":"2023-12-29T16:06:45.060393Z","shell.execute_reply":"2023-12-29T16:06:45.434174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nimport os\nos.chdir(r'/kaggle/working/')\nFileLink(r'/kaggle/working/UNet_3D_best_model_round3_128.keras')","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:00:22.476643Z","iopub.execute_input":"2023-12-29T16:00:22.477471Z","iopub.status.idle":"2023-12-29T16:00:22.484323Z","shell.execute_reply.started":"2023-12-29T16:00:22.477435Z","shell.execute_reply":"2023-12-29T16:00:22.483220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}